{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import altair as alt\n",
    "alt.renderers.enable('notebook')\n",
    "\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, RandomUnderSampler, EditedNearestNeighbours, RepeatedEditedNearestNeighbours\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/final_book_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../data/processed/reddit_df_with_dates.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns=['duck_dates', 'ask_dates'])\n",
    "df = df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df = df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1294.000000</td>\n",
       "      <td>1022.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1865.688563</td>\n",
       "      <td>2.529354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>124.642119</td>\n",
       "      <td>1.738716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1511.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1819.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1907.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1959.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date       target\n",
       "count  1294.000000  1022.000000\n",
       "mean   1865.688563     2.529354\n",
       "std     124.642119     1.738716\n",
       "min    1511.000000     0.000000\n",
       "25%    1819.000000     1.000000\n",
       "50%    1907.000000     2.000000\n",
       "75%    1959.000000     4.000000\n",
       "max    2016.000000     5.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['text'], keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        0\n",
       "info        2\n",
       "target    136\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>info</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1528</td>\n",
       "      <td>The book of the Courtier</td>\n",
       "      <td>0.0</td>\n",
       "      <td>then the soul freed from vice purged by studie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1569</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>his goodly frame the earth seems to me a steri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1592</td>\n",
       "      <td>the spanish tragedy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O eyes, no eyes, but fountains fraught with te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1569</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>firmament this majestical roof fretted with go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1623</td>\n",
       "      <td>macbeth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mine eyes are made the fools o the other sense...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date                      info  target  \\\n",
       "0  1528  The book of the Courtier     0.0   \n",
       "1  1569                    Hamlet     0.0   \n",
       "2  1592       the spanish tragedy     0.0   \n",
       "3  1569                    Hamlet     0.0   \n",
       "4  1623                   macbeth     0.0   \n",
       "\n",
       "                                                text  \n",
       "0  then the soul freed from vice purged by studie...  \n",
       "1  his goodly frame the earth seems to me a steri...  \n",
       "2  O eyes, no eyes, but fountains fraught with te...  \n",
       "3  firmament this majestical roof fretted with go...  \n",
       "4  mine eyes are made the fools o the other sense...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class LanguageTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, x_train):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x_train):\n",
    "        new_list = []\n",
    "        new_line = []\n",
    "        final_line = []\n",
    "        final_entry = []\n",
    "        for item in x_train:\n",
    "            new_list.append(item + ', ')\n",
    "            for list_item in new_list:\n",
    "                new_line.append(list_item.split())\n",
    "                for line in new_line:\n",
    "                    final_line = []\n",
    "                    for word in line:\n",
    "                        lemmatizer = WordNetLemmatizer()\n",
    "                        raw_text = str(word)\n",
    "                        string_lower_case = raw_text.lower()\n",
    "                        # new_text = string_lower_case.astype('U')\n",
    "                        retokenizer = RegexpTokenizer(r'[a-z]+')\n",
    "                        words = retokenizer.tokenize(string_lower_case)\n",
    "                        lemm_words = lemmatizer.lemmatize(\" \".join(words))\n",
    "                        final_line.append(lemm_words)\n",
    "\n",
    "                final_entry.append(final_line)\n",
    "\n",
    "\n",
    "        return final_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = LanguageTransformer()\n",
    "ct.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(raw_text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    raw_text = str(raw_text)\n",
    "    lower_case = raw_text.lower()\n",
    "    retokenizer = RegexpTokenizer(r'[a-z]+')\n",
    "    words = retokenizer.tokenize(lower_case)\n",
    "\n",
    "    return(lemmatizer.lemmatize(\" \".join(words)))\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Grid Search Target Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two preliminary instantiated vectorizers to be used in GridSearch function\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english',\n",
    "                        lowercase=True,\n",
    "                        ngram_range=(1, 2),\n",
    "                        strip_accents='unicode')\n",
    "\n",
    "tvec = TfidfVectorizer(stop_words='english',\n",
    "                        ngram_range=(1, 3),\n",
    "                        encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_list = [\n",
    "    [0, 1670, 1800, 1870, 1910, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1870, 1910, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1870, 1920, 1945, np.inf],\n",
    "    [0, 1670, 1800, 1870, 1920, 1945, np.inf],\n",
    "    [0, 1670, 1800, 1870, 1920, 1960, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1920, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1920, 1950, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1910, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1930, 1975, np.inf],\n",
    "    [0, 1700, 1800, 1870, 1910, 1945, np.inf],\n",
    "    [0, 1700, 1830, 1890, 1910, 1945, np.inf],\n",
    "    [0, 1700, 1830, 1870, 1920, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1870, 1920, 1975, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1920, 1975, np.inf],\n",
    "    [0, 1600, 1700, 1800, 1900, 1950, np.inf],\n",
    "    [0, 1670, 1830, 1920, 1950, 1990, np.inf],\n",
    "    [0, 1700, 1830, 1890, 1910, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1910, 1950, 1990, np.inf],\n",
    "    [0, 1670, 1870, 1910, 1950, 1990, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1920, 1990, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1930, 1990, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1920, 1960, np.inf]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets(bin_list, model, vectorizer, df=df):\n",
    "    \n",
    "    '''\n",
    "    Function to grid search and find the optimal target for time periods\n",
    "    bin_list: several ways to classify the targets\n",
    "    model: model to instantiate\n",
    "    vectorizer: either cvec or tvec\n",
    "    '''\n",
    "    \n",
    "    for b in bin_list:\n",
    "        bins = b\n",
    "        bin_names = range(0, 6)\n",
    "        df['target'] = pd.cut(df['date'], bins, labels=bin_names)\n",
    "        df.groupby('target').count()\n",
    "\n",
    "        #train test split\n",
    "        x = df['text']\n",
    "        y = df['target']\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.8, random_state=42, shuffle=True, stratify=y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #vectorizing\n",
    "        train_data = vectorizer.fit_transform(x_train.apply(lambda x: np.str_(x)))\n",
    "        test_data = vectorizer.transform(x_test.apply(lambda x: np.str_(x)))\n",
    "        \n",
    "       \n",
    "        \n",
    "        #instantiating, fitting, and scoring the model\n",
    "        model = model\n",
    "        model.fit(train_data, y_train)\n",
    "        score = model.score(test_data, y_test)\n",
    "       \n",
    "        print(f' Test Accuracy of Bin {bins}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy of Bin [0, 1670, 1800, 1870, 1910, 1945, inf]: 0.6909090909090909\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1870, 1910, 1945, inf]: 0.6727272727272727\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1945, inf]: 0.6681818181818182\n",
      " Test Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1945, inf]: 0.7045454545454546\n",
      " Test Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1960, inf]: 0.6818181818181818\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1945, inf]: 0.7090909090909091\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1950, inf]: 0.7045454545454546\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1910, 1945, inf]: 0.6818181818181818\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1930, 1975, inf]: 0.7363636363636363\n",
      " Test Accuracy of Bin [0, 1700, 1800, 1870, 1910, 1945, inf]: 0.6818181818181818\n",
      " Test Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.6727272727272727\n",
      " Test Accuracy of Bin [0, 1700, 1830, 1870, 1920, 1945, inf]: 0.6363636363636364\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1975, inf]: 0.6863636363636364\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1975, inf]: 0.6954545454545454\n",
      " Test Accuracy of Bin [0, 1600, 1700, 1800, 1900, 1950, inf]: 0.6818181818181818\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1920, 1950, 1990, inf]: 0.7181818181818181\n",
      " Test Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.6727272727272727\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1910, 1950, 1990, inf]: 0.6909090909090909\n",
      " Test Accuracy of Bin [0, 1670, 1870, 1910, 1950, 1990, inf]: 0.6954545454545454\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1990, inf]: 0.6772727272727272\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1930, 1990, inf]: 0.6954545454545454\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1960, inf]: 0.7090909090909091\n"
     ]
    }
   ],
   "source": [
    "make_targets(bin_list, model=LogisticRegression(class_weight='balanced'), vectorizer=cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy of Bin [0, 1670, 1800, 1870, 1910, 1945, inf]: 0.5454545454545454\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1870, 1910, 1945, inf]: 0.5454545454545454\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1945, inf]: 0.5181818181818182\n",
      " Test Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1945, inf]: 0.5272727272727272\n",
      " Test Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1960, inf]: 0.55\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1945, inf]: 0.5454545454545454\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1950, inf]: 0.5272727272727272\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1910, 1945, inf]: 0.55\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1930, 1975, inf]: 0.55\n",
      " Test Accuracy of Bin [0, 1700, 1800, 1870, 1910, 1945, inf]: 0.5545454545454546\n",
      " Test Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.5318181818181819\n",
      " Test Accuracy of Bin [0, 1700, 1830, 1870, 1920, 1945, inf]: 0.5409090909090909\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1975, inf]: 0.509090909090909\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1975, inf]: 0.5727272727272728\n",
      " Test Accuracy of Bin [0, 1600, 1700, 1800, 1900, 1950, inf]: 0.5681818181818182\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1920, 1950, 1990, inf]: 0.5636363636363636\n",
      " Test Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.5545454545454546\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1910, 1950, 1990, inf]: 0.509090909090909\n",
      " Test Accuracy of Bin [0, 1670, 1870, 1910, 1950, 1990, inf]: 0.5545454545454546\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1990, inf]: 0.5863636363636363\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1930, 1990, inf]: 0.5272727272727272\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1960, inf]: 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "make_targets(bin_list, model=RandomForestClassifier(), vectorizer=cvec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_targets(bin_list, model=RandomForestClassifier(), vectorizer=tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy of Bin [0, 1670, 1800, 1870, 1910, 1945, inf]: 0.6909090909090909\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1870, 1910, 1945, inf]: 0.6909090909090909\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1945, inf]: 0.6636363636363637\n",
      " Test Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1945, inf]: 0.7090909090909091\n",
      " Test Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1960, inf]: 0.6772727272727272\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1945, inf]: 0.7\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1950, inf]: 0.7272727272727273\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1910, 1945, inf]: 0.6863636363636364\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1930, 1975, inf]: 0.6727272727272727\n",
      " Test Accuracy of Bin [0, 1700, 1800, 1870, 1910, 1945, inf]: 0.6772727272727272\n",
      " Test Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.6681818181818182\n",
      " Test Accuracy of Bin [0, 1700, 1830, 1870, 1920, 1945, inf]: 0.6318181818181818\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1975, inf]: 0.6454545454545455\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1975, inf]: 0.6772727272727272\n",
      " Test Accuracy of Bin [0, 1600, 1700, 1800, 1900, 1950, inf]: 0.6409090909090909\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1920, 1950, 1990, inf]: 0.6318181818181818\n",
      " Test Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.6681818181818182\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1910, 1950, 1990, inf]: 0.5909090909090909\n",
      " Test Accuracy of Bin [0, 1670, 1870, 1910, 1950, 1990, inf]: 0.6363636363636364\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1990, inf]: 0.7136363636363636\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1930, 1990, inf]: 0.6\n",
      " Test Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1960, inf]: 0.6863636363636364\n"
     ]
    }
   ],
   "source": [
    "make_targets(bin_list, model=LogisticRegression(class_weight='balanced'), vectorizer=tvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>info</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>148</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196</td>\n",
       "      <td>196</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>269</td>\n",
       "      <td>268</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  info  text\n",
       "target                  \n",
       "0        149   148   149\n",
       "1        163   163   163\n",
       "2        196   196   196\n",
       "3        148   148   148\n",
       "4        172   172   172\n",
       "5        269   268   269"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 1670, 1830, 1890, 1920, 1950, np.inf] #Performed well on all\n",
    "names = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "df['target'] = pd.cut(df['date'], bins, labels=names)\n",
    "\n",
    "df.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>info</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1528</td>\n",
       "      <td>The book of the Courtier</td>\n",
       "      <td>0</td>\n",
       "      <td>then the soul freed from vice purged by studie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1569</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>0</td>\n",
       "      <td>his goodly frame the earth seems to me a steri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date                      info target  \\\n",
       "0  1528  The book of the Courtier      0   \n",
       "1  1569                    Hamlet      0   \n",
       "\n",
       "                                                text  \n",
       "0  then the soul freed from vice purged by studie...  \n",
       "1  his goodly frame the earth seems to me a steri...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      0\n",
       "info      2\n",
       "target    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date         int64\n",
       "info        object\n",
       "target    category\n",
       "text        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target = df.target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/cleaned/book_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countvectorizer Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "stop.extend(['one', 'word', 'us', 'could', 'go', 'let', 'see', 'would', 'two', 'said', 'made', 'brutus', 'dryden']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words=stop)\n",
    "unigrams = pd.DataFrame(cvec.fit_transform(df['text']).todense(), columns=cvec.get_feature_names())\n",
    "unigrams['target'] = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target0_top_uni = unigrams.groupby('target').sum().T.sort_values(by=0, ascending=False)[[0]].head(20)\n",
    "target1_top_uni = unigrams.groupby('target').sum().T.sort_values(by=1, ascending=False)[[0]].head(20)\n",
    "target2_top_uni = unigrams.groupby('target').sum().T.sort_values(by=2, ascending=False)[[0]].head(20)\n",
    "target3_top_uni = unigrams.groupby('target').sum().T.sort_values(by=3, ascending=False)[[0]].head(20)\n",
    "target4_top_uni = unigrams.groupby('target').sum().T.sort_values(by=4, ascending=False)[[0]].head(20)\n",
    "target5_top_uni = unigrams.groupby('target').sum().T.sort_values(by=5, ascending=False)[[0]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gram_df(uni_df):\n",
    "    unigram_df = uni_df.rename(columns={0: 'frequency'})\n",
    "    unigram_df = unigram_df.reset_index()\n",
    "    unigram_df = unigram_df.rename(columns={'index': 'word'})\n",
    "    return unigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the clean_uni_df function to create individual dataframes by target\n",
    "\n",
    "target0 = clean_gram_df(target0_top_uni)\n",
    "target1 = clean_gram_df(target1_top_uni)\n",
    "target2 = clean_gram_df(target2_top_uni)\n",
    "target3 = clean_gram_df(target3_top_uni)\n",
    "target4 = clean_gram_df(target4_top_uni)\n",
    "target5 = clean_gram_df(target5_top_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def altair_chart(target, color='darkred'):\n",
    "    '''\n",
    "    Input: target dataframe and color\n",
    "    Output: altair chart\n",
    "    '''\n",
    "    \n",
    "    Chart = alt.Chart(target).mark_bar(color=color).encode(\n",
    "        x='word',\n",
    "        y='frequency')\n",
    "    \n",
    "    return Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_chart(target0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_chart(target1, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_chart(target2, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_chart(target3, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_chart(target4, color='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_chart(target5, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer for Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivec = CountVectorizer(stop_words=stop, ngram_range=(2, 2))\n",
    "bigrams = pd.DataFrame(bivec.fit_transform(df['text']).todense(), columns=bivec.get_feature_names())\n",
    "bigrams['target'] = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target0_bi = bigrams.groupby('target').sum().T.sort_values(by=0, ascending=False)[[0]].head(20)\n",
    "target1_bi = bigrams.groupby('target').sum().T.sort_values(by=1, ascending=False)[[0]].head(20)\n",
    "target2_bi = bigrams.groupby('target').sum().T.sort_values(by=2, ascending=False)[[0]].head(20)\n",
    "target3_bi = bigrams.groupby('target').sum().T.sort_values(by=3, ascending=False)[[0]].head(20)\n",
    "target4_bi = bigrams.groupby('target').sum().T.sort_values(by=4, ascending=False)[[0]].head(20)\n",
    "target5_bi = bigrams.groupby('target').sum().T.sort_values(by=5, ascending=False)[[0]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target0 = clean_gram_df(target0_bi)\n",
    "target1 = clean_gram_df(target1_bi)\n",
    "target2 = clean_gram_df(target2_bi)\n",
    "target3 = clean_gram_df(target3_bi)\n",
    "target4 = clean_gram_df(target4_bi)\n",
    "target5 = clean_gram_df(target5_bi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_chart(target0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_chart(target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_chart(target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is so small, there is not enough data to find bivecs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target0 = df[df.target == 0]['text']\n",
    "target1 = df[df.target == 1]['text']\n",
    "target2 = df[df.target == 2]['text']\n",
    "target3 = df[df.target == 3]['text']\n",
    "target4 = df[df.target == 4]['text']\n",
    "target5 = df[df.target == 5]['text']\n",
    "target6 = df[df.target == 6]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_graph(target_group):\n",
    "    \n",
    "    lda = LDA(n_components=3, random_state=42)\n",
    "    t = cvec.fit_transform(target_group)\n",
    "    lda_t = lda.fit_transform(t)\n",
    "    \n",
    "    return pyLDAvis.sklearn.prepare(lda, t, cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_graph(target0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_graph(target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_graph(target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LDA_graph(target3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_graph(target4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_graph(target5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyzer.polarity_scores(sentence)\n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df.text.apply(sentiment_analyzer_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent = json_normalize(df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent = df_sent.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent = df_sent.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join((df_sent), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/cleaned/df_with_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound = df.groupby('target', as_index=False)['compound'].mean()\n",
    "neg = df.groupby('target', as_index=False)['neg'].mean()\n",
    "neu = df.groupby('target', as_index=False)['neu'].mean()\n",
    "pos = df.groupby('target', as_index=False)['pos'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_chart = pd.concat([compound, neg, neu, pos], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_chart = sentiment_chart.loc[:, ~sentiment_chart.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = alt.Chart(sentiment_chart).mark_bar(color='black').encode(\n",
    "    x='target:O',\n",
    "    y='sum(compound):Q'\n",
    ")\n",
    "\n",
    "B = alt.Chart(sentiment_chart).mark_bar(color='red').encode(\n",
    "    x='target:O',\n",
    "    y='sum(neg):Q'\n",
    ")\n",
    "\n",
    "C = alt.Chart(sentiment_chart).mark_bar(color='purple').encode(\n",
    "    x='target:O',\n",
    "    y='sum(neu):Q'\n",
    ")\n",
    "\n",
    "D = alt.Chart(sentiment_chart).mark_bar().encode(\n",
    "    x='target:O',\n",
    "    y='sum(pos):Q'\n",
    ")\n",
    "\n",
    "A | B | C | D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_point().encode(\n",
    "    x='target',\n",
    "    y='compound',\n",
    "    color='target',\n",
    ").facet(column='Origin:N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english',\n",
    "                        lowercase=True,\n",
    "                        ngram_range=(2, 2),\n",
    "                        strip_accents='unicode')\n",
    "\n",
    "tvec = TfidfVectorizer(stop_words='english',\n",
    "                        ngram_range=(1, 3),\n",
    "                        encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = cvec.fit_transform(X_train)\n",
    "X_test_counts = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aadam aziz</th>\n",
       "      <th>abalone shells</th>\n",
       "      <th>abandon benefits</th>\n",
       "      <th>abandon intended</th>\n",
       "      <th>abandon pair</th>\n",
       "      <th>abandoned beach</th>\n",
       "      <th>abandoned case</th>\n",
       "      <th>abandoned evidence</th>\n",
       "      <th>abandoned framework</th>\n",
       "      <th>abandoned heroine</th>\n",
       "      <th>...</th>\n",
       "      <th>zulu burmese</th>\n",
       "      <th>zulu evening</th>\n",
       "      <th>zulu impi</th>\n",
       "      <th>zulu manager</th>\n",
       "      <th>zulu people</th>\n",
       "      <th>zulu wish</th>\n",
       "      <th>zulu woman</th>\n",
       "      <th>zulu wot</th>\n",
       "      <th>zurich staring</th>\n",
       "      <th>zygote lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140914 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aadam aziz  abalone shells  abandon benefits  abandon intended  \\\n",
       "0           0               0                 0                 0   \n",
       "1           0               0                 0                 0   \n",
       "2           0               0                 0                 0   \n",
       "3           0               0                 0                 0   \n",
       "4           0               0                 0                 0   \n",
       "\n",
       "   abandon pair  abandoned beach  abandoned case  abandoned evidence  \\\n",
       "0             0                0               0                   0   \n",
       "1             0                0               0                   0   \n",
       "2             0                0               0                   0   \n",
       "3             0                0               0                   0   \n",
       "4             0                0               0                   0   \n",
       "\n",
       "   abandoned framework  abandoned heroine  ...  zulu burmese  zulu evening  \\\n",
       "0                    0                  0  ...             0             0   \n",
       "1                    0                  0  ...             0             0   \n",
       "2                    0                  0  ...             0             0   \n",
       "3                    0                  0  ...             0             0   \n",
       "4                    0                  0  ...             0             0   \n",
       "\n",
       "   zulu impi  zulu manager  zulu people  zulu wish  zulu woman  zulu wot  \\\n",
       "0          0             0            0          0           0         0   \n",
       "1          0             0            0          0           0         0   \n",
       "2          0             0            0          0           0         0   \n",
       "3          0             0            0          0           0         0   \n",
       "4          0             0            0          0           0         0   \n",
       "\n",
       "   zurich staring  zygote lost  \n",
       "0               0            0  \n",
       "1               0            0  \n",
       "2               0            0  \n",
       "3               0            0  \n",
       "4               0            0  \n",
       "\n",
       "[5 rows x 140914 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counts = pd.DataFrame(X_train_counts.todense(), columns=cvec.get_feature_names())\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.4909090909090909\n"
     ]
    }
   ],
   "source": [
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train_counts, y_train)\n",
    "y_pred = model1.predict(X_test_counts)\n",
    "print(model1.score(X_train_counts, y_train))\n",
    "print(model1.score(X_test_counts, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy Score: 0.4909090909090909\n",
      " Precision Score: [1.         1.         1.         1.         0.9        0.29487179]\n",
      " Recall Score: [0.38888889 0.08333333 0.32       0.375      0.5625     1.        ]\n"
     ]
    }
   ],
   "source": [
    "def classification_metrics(y_test, y_pred):\n",
    "    print(f' Accuracy Score: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f' Precision Score: {precision_score(y_test, y_pred, average = None)}')\n",
    "    print(f' Recall Score: {recall_score(y_test, y_pred, average = None)}')\n",
    "    \n",
    "classification_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalance Learn with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8780487804878049\n",
      "0.5181818181818182\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE()\n",
    "X_reb, y_reb = sm.fit_sample(X_train_counts, y_train)\n",
    "\n",
    "model1.fit(X_reb, y_reb)\n",
    "print(model1.score(X_reb, y_reb))\n",
    "print(model1.score(X_test_counts, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy Score: 0.5181818181818182\n",
      " Precision Score: [0.38636364 0.42857143 0.88888889 0.69230769 0.38461538 0.90909091]\n",
      " Recall Score: [0.94444444 0.25       0.32       0.5625     0.625      0.43478261]\n"
     ]
    }
   ],
   "source": [
    "classification_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8170731707317073\n",
      "Test score: 0.6181818181818182\n"
     ]
    }
   ],
   "source": [
    "model2 = LogisticRegression(C = 0.001,\n",
    "                         class_weight = 'balanced',\n",
    "                         multi_class = 'multinomial',\n",
    "                         penalty= 'l2',\n",
    "                         solver= 'sag')\n",
    "model2.fit(X_reb, y_reb)\n",
    "print(f'Train score: {model2.score(X_reb, y_reb)}')\n",
    "print(f'Test score: {model2.score(X_test_counts, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy Score: 0.6181818181818182\n",
      " Precision Score: [1.         0.55555556 0.65384615 0.61111111 0.75       0.5       ]\n",
      " Recall Score: [0.38888889 0.41666667 0.68       0.6875     0.5625     0.82608696]\n"
     ]
    }
   ],
   "source": [
    "classification_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Exploration of Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame(y_pred, y_test)\n",
    "comparison = comparison.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = comparison.rename(columns={0: 'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  prediction\n",
       "0       0           5\n",
       "1       3           2\n",
       "2       0           0\n",
       "3       4           4\n",
       "4       3           2"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison['prediction'] = comparison['prediction'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison['correct'] = np.where(comparison['target'] == comparison['prediction'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = comparison.rename(columns={0: 'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.target = comparison.target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  prediction  correct\n",
       "105       5           5        1\n",
       "106       2           2        1\n",
       "107       3           3        1\n",
       "108       3           2        0\n",
       "109       5           5        1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  prediction  correct\n",
       "0       0           5        0\n",
       "1       3           2        0\n",
       "2       0           0        1\n",
       "3       4           4        1\n",
       "4       3           2        0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison['difference'] = abs(comparison.target - comparison.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>correct</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  prediction  correct  difference\n",
       "0       0           5        0           5\n",
       "1       3           2        0           1\n",
       "2       0           0        1           0\n",
       "3       4           4        1           0\n",
       "4       3           2        0           1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7909090909090909"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borderline_dates = len(comparison[comparison['difference'] <= 1]) / len(comparison['difference'])\n",
    "borderline_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
