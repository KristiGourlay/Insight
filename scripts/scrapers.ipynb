{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "from glob import glob\n",
    "import datetime\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import os\n",
    "from time import sleep\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content was scraped using a wget provided by the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('../data/raw/Gutenberg/txt/*.txt')\n",
    "\n",
    "book_df = pd.DataFrame(columns=['text', 'info', 'date', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_book_info(files):\n",
    "    '''\n",
    "    Input: list of files\n",
    "    Output: first section of each file which contains book information\n",
    "    '''\n",
    "    book_info = []\n",
    "    for file in files:\n",
    "        open_file = open(file, 'r', encoding= \"ISO-8859-1\")\n",
    "        read_file = open_file.read()[:300]\n",
    "        read_file = read_file.replace(' ', '').split()\n",
    "        book_info.append(read_file)\n",
    "\n",
    "    return book_info\n",
    "\n",
    "\n",
    "book_information = collect_book_info(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_book_text(files):\n",
    "    '''\n",
    "    Input: list of files\n",
    "    Output: portion of each file that contains excerpt\n",
    "    '''\n",
    "    book_text = []\n",
    "    for file in files:\n",
    "        open_file = open(file, 'r', encoding= \"ISO-8859-1\")\n",
    "        read_file = open_file.read()[1500:2300].splitlines()\n",
    "        book_text.append(read_file)\n",
    "\n",
    "    return book_text\n",
    "\n",
    "book_text = collect_book_text(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding information to dataframe\n",
    "book_df['info'] = book_information\n",
    "book_df['text'] = book_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_half_words(raw_text):\n",
    "    '''\n",
    "    Input: column in df that has excerpts extracted from files\n",
    "    Output: excerpts with first and last words dropped to elimiate half words\n",
    "    '''\n",
    "    words = str(raw_text).split()\n",
    "    result = words[1:-2]\n",
    "    return result\n",
    "\n",
    "book_df['text'] = book_df['text'].apply(delete_half_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Date Information\n",
    "def create_date(book_info):\n",
    "    date_info = []\n",
    "    for info in book_information:\n",
    "        info = str(info)\n",
    "        info = re.findall(r'(\\d{4})', info)\n",
    "        date_info.append(info)\n",
    "\n",
    "    return date_info\n",
    "\n",
    "book_dates = create_date(book_information)\n",
    "book_df['date'] = book_dates\n",
    "\n",
    "book_df = book_df.replace('[]', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df['date'] = book_df['date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df['date'] = book_df['date'].str.strip('[]')\n",
    "book_df['date'] = book_df['date'].str.strip(\"''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristigourlay/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "mask = (book_df['date'].str.len() > 4)\n",
    "\n",
    "len(mask)\n",
    "book_df[mask] = book_df.loc[mask].date = 'NaN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stylist Magazine Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "url = 'http://stylist.co.uk/books/the-best-100-closing-lines-from-books/123681'\n",
    "res = requests.get(url)\n",
    "soup = bs(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = []\n",
    "for link in soup.find_all('h3', {'class': 'css-r1u8am'}):\n",
    "    ta_dict = {}\n",
    "    ta_dict['title'] = link.text\n",
    "    books.append(ta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = []\n",
    "for link in soup.find_all('div', {'class': 'css-dbbd7o'}):\n",
    "    tr_dict = {}\n",
    "    tr_dict['quote'] = link.text\n",
    "    quotes.append(tr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_info = pd.DataFrame(books, quotes)\n",
    "book_info = book_info.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_quotes = book_info['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quote(list_of_quotes):\n",
    "    '''\n",
    "    Input: List of dictionaries\n",
    "    Output: Unpacked dictionary, quotes (values) saved to list'''\n",
    "    quotes = []\n",
    "    num = len(list_of_quotes)\n",
    "    for i in range(0, num):\n",
    "        new_quote = list_of_quotes[i]['quote'].splitlines()[0]\n",
    "        quotes.append(new_quote)\n",
    "    \n",
    "    return quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "book_info['index'] = extract_quote(list_of_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_info = book_info.rename(columns={'index': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = book_info[book_info['text'].map(len) > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = 'NaN'\n",
    "df['date'] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('quote_scrape.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.reddit.com/r/books/comments/1mqfzt/what_is_the_most_powerful_chapter_paragraph_or/.json'\n",
    "# url = 'https://thoughtcatalog.com/charlie-shaw/2013/09/34-profound-excerpts-from-classic-literature-that-will-change-your-day/.json'\n",
    "url = 'https://www.reddit.com/r/books/comments/35wv34/whats_the_most_beautiful_paragraph_or_sentence/.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'My User Agent 1.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(url, after=''):\n",
    "    params = {'after': after}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    return response.json()[1]['data']['children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_post(post):\n",
    "    keep = ['subreddit', 'title', 'body', 'name'] \n",
    "    return {k:v for k, v in post['data'].items() if k in keep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(page):\n",
    "    after = ''\n",
    "    posts = []\n",
    "    for post in page:\n",
    "        post = parse_post(post)\n",
    "        after = post['name']\n",
    "        posts.append(post)\n",
    "    return posts, after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_subreddit(subreddit, pages=4):\n",
    "    url = subreddit\n",
    "    after = ''\n",
    "    all_posts = []\n",
    "    for i in range(pages):\n",
    "        print(f'Fetching Page {i + 1}')\n",
    "        page = fetch_page(url, after)\n",
    "        posts, after = parse_page(page)\n",
    "        all_posts.extend(posts)\n",
    "        time.sleep(5)\n",
    "    return all_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = fetch_subreddit(url, pages=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.DataFrame(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = reddit_df.dropna()\n",
    "reddit_df = reddit_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_posts(posts):\n",
    "    new_posts = []\n",
    "    for post in posts:\n",
    "        post = post.replace('\\n', '')\n",
    "        new_posts.append(post)\n",
    "        \n",
    "    return new_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = reddit_df['body'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['body'] = clean_posts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column(df, col):\n",
    "    '''\n",
    "    Input: dataframe and specified column\n",
    "    Output: column split into two columns by the last existence of a dash (how a majority of redditor's split excerpt and book)'''\n",
    "    new = df[col].str.rsplit('-', n=1, expand=True)\n",
    "    df['text'] = new[0]\n",
    "    df['info'] = new[1]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = split_column(reddit_df, 'body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('reddit_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('reddit_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('reddit_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Scraping (Selenium) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/reddit_data.csv', index_col=0)\n",
    "# browser = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../data/processed/quote_scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['name', 'subreddit', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns=['target', 'date'])\n",
    "df2 = df2.rename(columns={'title': 'info'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = df['info'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_queries = []\n",
    "for item in title_list:\n",
    "    search_queries.append(f'when was {item} published?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape for Google.com\n",
    "\n",
    "dates  = []\n",
    "browser = webdriver.Firefox()\n",
    "for p in search_queries:\n",
    "    browser.get('http://www.google.com')\n",
    "    search = browser.find_element_by_name('q')\n",
    "    search.send_keys(f'\"{p}\"')\n",
    "    search.send_keys(Keys.RETURN) # hit return after you enter search text\n",
    "    time.sleep(60) #sleep for 20 seconds\n",
    "    \n",
    "    try:\n",
    "        result = browser.find_element_by_xpath('.//div[@class=\"Z0LcW\"]') \n",
    "        result = result.get_attribute('innerHTML') #if date number exists, append to list\n",
    "    except:\n",
    "        result = 'NaN' #if date number does not exist, append \"NaN\"\n",
    "\n",
    "    dates.append(result)\n",
    "browser.quit()\n",
    "\n",
    "# Googles selenium scraper dealt with recaptchas more often so the sleeps had to be longer, and it would need to be \n",
    "#stopped and restarted at the index spot where it left off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_years(text):\n",
    "    new_list_dates = []\n",
    "    for t in text:\n",
    "        date = re.findall(r'(\\d{4})', t)\n",
    "        new_list_dates.append(date)\n",
    "                          \n",
    "    return new_list_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['google_dates'] = extract_years(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>info</th>\n",
       "      <th>google_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Really, the whole paragraph is good, but in pa...</td>\n",
       "      <td>A Farewell to Arms</td>\n",
       "      <td>[1929]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I looked at the stars, and considered how awf...</td>\n",
       "      <td>Dickens, Great Expectations</td>\n",
       "      <td>[1861]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"As the days went by, the evolution of like in...</td>\n",
       "      <td>Jack London</td>\n",
       "      <td>[1916]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Where else? I belong to a lost generation and...</td>\n",
       "      <td>Umberto Eco, Foucault's Pendulum</td>\n",
       "      <td>[1988]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;gt;Have you ever been in love? Horrible isn't...</td>\n",
       "      <td>The Sandman, Neil Gaiman</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Some men are born mediocre, some men achieve m...</td>\n",
       "      <td>Catch 22</td>\n",
       "      <td>[1961]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Down there are people who will follow any drag...</td>\n",
       "      <td>The Patrician Vetinari</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This sentence has five words. Here are five mo...</td>\n",
       "      <td>Gary Provost</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e live in time - it holds us and molds us - bu...</td>\n",
       "      <td>Sense of an Ending by Julian Barnes</td>\n",
       "      <td>[2011]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Out of the little grove, away from the baffled...</td>\n",
       "      <td>The Amber Spyglass, Phillip Paulman</td>\n",
       "      <td>[2000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Look again at that dot. Thats here. Thats home...</td>\n",
       "      <td>Carl Sagan, Pale Blue Dot</td>\n",
       "      <td>[1994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"And in that very moment, away behind in some ...</td>\n",
       "      <td>Return of the King by J.R.R Tolkien</td>\n",
       "      <td>[1955]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>“Strange memories on this nervous night in Las...</td>\n",
       "      <td>Hunter S Thompson, Fear and loathing in Las V...</td>\n",
       "      <td>[1971]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Anybody can look at a pretty girl and see a pr...</td>\n",
       "      <td>Robert A. Heinlein,  Stranger in a Strange Land</td>\n",
       "      <td>[1961]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Here I recaptured the former beauty, a young ...</td>\n",
       "      <td>Albert Camus, *Return to Tipasa*</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Naw, Jem. I think that there is just one kind...</td>\n",
       "      <td>To Kill a Mockingbirg</td>\n",
       "      <td>[1960]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Let us go then, you and I,When the evening is ...</td>\n",
       "      <td>T.S. Eliot</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>“I looked for you on the Trident,” Ned said to...</td>\n",
       "      <td>A Game of Thrones</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"But then they danced down the streets like di...</td>\n",
       "      <td>On the Road, Jack Kerouac</td>\n",
       "      <td>[1951]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>For West is where we all plan to go some day. ...</td>\n",
       "      <td>All the Kings Men, Robert Penn Warren</td>\n",
       "      <td>[1946]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(I've been lurking reddit for a while... Two y...</td>\n",
       "      <td>Joseph Conrad,  \"The Heart of Darkness</td>\n",
       "      <td>[1902]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"It was the crossbows that decided Turkos, alt...</td>\n",
       "      <td>The Fell Sword, by Miles Cameron</td>\n",
       "      <td>[2013]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"In the beginning, the Universe was created. T...</td>\n",
       "      <td>Hitchhiker's Guide to the Galaxy</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>**\"**An artisan without memories, whose only d...</td>\n",
       "      <td>One Hundred Years of Solitude</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"He spun round with a sort of guilty bound, li...</td>\n",
       "      <td>P.G. Wodehouse, *Joy in the Morning*</td>\n",
       "      <td>[1946]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Be soft. Do not let the world make you hard. ...</td>\n",
       "      <td>Kurt Vonnegut, Cats Cradle</td>\n",
       "      <td>[1963]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&amp;gt; And the ship went out into the High Sea a...</td>\n",
       "      <td>The Return of the King, by J. R. R. Tolkien</td>\n",
       "      <td>[1955]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"With his symbolic helmet numbered 451 on his ...</td>\n",
       "      <td>Farrenheit 451</td>\n",
       "      <td>[1953]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Forthwith a change came over the waters, and t...</td>\n",
       "      <td>Heart of Darkness</td>\n",
       "      <td>[1902]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>“When a child first catches adults out -- when...</td>\n",
       "      <td>Steinbeck, East of EdenThat book is filled wi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>\"I lost track after a while, happy to be home,...</td>\n",
       "      <td>Middlesex</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>\"The men began singing, a grave, slow song tha...</td>\n",
       "      <td>Suite Francaise</td>\n",
       "      <td>[2004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>\"'When the day shall come, that we do part,' h...</td>\n",
       "      <td>The Fiery Cross</td>\n",
       "      <td>[2001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>\"I lingered round them, under that benign sky;...</td>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>[1847]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>\"His body stirs beneath the sheets. He twists ...</td>\n",
       "      <td>The Hand That First Held Mine</td>\n",
       "      <td>[2009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>''I never saw any of them again — except the c...</td>\n",
       "      <td>The Long Goodbye</td>\n",
       "      <td>[1953]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>\"She watched as Sandy Forsyth walked across th...</td>\n",
       "      <td>Winter in Madrid</td>\n",
       "      <td>[2006]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>\"I went on my way. A stormy wind rattled the s...</td>\n",
       "      <td>The Pianist</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>\"This is not a full circle. It's Life carrying...</td>\n",
       "      <td>Don't Let's Go to the Dogs Tonight</td>\n",
       "      <td>[2001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>\"Yes, they will trample me underfoot, the numb...</td>\n",
       "      <td>Midnight's Children</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>\"The white floodlight shines through the wispy...</td>\n",
       "      <td>A Hundred and One Days</td>\n",
       "      <td>[2003]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>\"It was then that I began to sit on my bed and...</td>\n",
       "      <td>Cider With Rosie</td>\n",
       "      <td>[1959]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>\"He now has more patients than the devil himse...</td>\n",
       "      <td>Madame Bovary</td>\n",
       "      <td>[1856]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>\"He turned away to give them time to pull them...</td>\n",
       "      <td>Lord of the Flies</td>\n",
       "      <td>[1954]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>\"Of course, it's only superstition, just for f...</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>[1991]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>\"And here she is, herself, Clarissa, not Mrs. ...</td>\n",
       "      <td>The Hours</td>\n",
       "      <td>[1998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>\"The broken flower drooped over Ben's fist and...</td>\n",
       "      <td>The Sound and the Fury</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>\"'Rest assured, our father, rest assured. The ...</td>\n",
       "      <td>The Good Earth</td>\n",
       "      <td>[1931]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>\"This stone is entirely blank. The only though...</td>\n",
       "      <td>Les Miserables</td>\n",
       "      <td>[1862]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>\"Slowly, very slowly, like two unhurried compa...</td>\n",
       "      <td>Brave New World</td>\n",
       "      <td>[1932]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>\"I got to light out for the Territory ahead of...</td>\n",
       "      <td>Adventures of Huckleberry Finn</td>\n",
       "      <td>[1884]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>\"Lastly, she pictured to herself how this same...</td>\n",
       "      <td>Alice's Adventures in Wonderland</td>\n",
       "      <td>[1865]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>\"When they finally did dare it, at first with ...</td>\n",
       "      <td>Perfume: The Story of a Murderer</td>\n",
       "      <td>[1985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>\"And so we stayed out in the garden of the old...</td>\n",
       "      <td>Man and Wife</td>\n",
       "      <td>[1870]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>\"But, in spite of these deficiencies, the wish...</td>\n",
       "      <td>Emma</td>\n",
       "      <td>[1815]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>\"Archie, for one, watched the mouse. He watche...</td>\n",
       "      <td>White Teeth</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>\"Might I trouble you then to be ready in half ...</td>\n",
       "      <td>The Hound of the Baskervilles</td>\n",
       "      <td>[1902]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>\"My personal rollercoaster. Not so much a roll...</td>\n",
       "      <td>Any Human Heart</td>\n",
       "      <td>[2002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>\"The offing was barred by a black bank of clou...</td>\n",
       "      <td>Heart of Darkness</td>\n",
       "      <td>[1902]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>\"He didn't think about it, he went straight to...</td>\n",
       "      <td>The Outcast</td>\n",
       "      <td>[1918]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Really, the whole paragraph is good, but in pa...   \n",
       "1    \"I looked at the stars, and considered how awf...   \n",
       "2    \"As the days went by, the evolution of like in...   \n",
       "3    \"Where else? I belong to a lost generation and...   \n",
       "4    &gt;Have you ever been in love? Horrible isn't...   \n",
       "5    Some men are born mediocre, some men achieve m...   \n",
       "6    Down there are people who will follow any drag...   \n",
       "7    This sentence has five words. Here are five mo...   \n",
       "8    e live in time - it holds us and molds us - bu...   \n",
       "9    Out of the little grove, away from the baffled...   \n",
       "10   Look again at that dot. Thats here. Thats home...   \n",
       "11   \"And in that very moment, away behind in some ...   \n",
       "12   “Strange memories on this nervous night in Las...   \n",
       "13   Anybody can look at a pretty girl and see a pr...   \n",
       "14   \"Here I recaptured the former beauty, a young ...   \n",
       "15   \"Naw, Jem. I think that there is just one kind...   \n",
       "16   Let us go then, you and I,When the evening is ...   \n",
       "17   “I looked for you on the Trident,” Ned said to...   \n",
       "18   \"But then they danced down the streets like di...   \n",
       "19   For West is where we all plan to go some day. ...   \n",
       "20   (I've been lurking reddit for a while... Two y...   \n",
       "21   \"It was the crossbows that decided Turkos, alt...   \n",
       "22   \"In the beginning, the Universe was created. T...   \n",
       "23   **\"**An artisan without memories, whose only d...   \n",
       "24   \"He spun round with a sort of guilty bound, li...   \n",
       "25   \"Be soft. Do not let the world make you hard. ...   \n",
       "26   &gt; And the ship went out into the High Sea a...   \n",
       "27   \"With his symbolic helmet numbered 451 on his ...   \n",
       "28   Forthwith a change came over the waters, and t...   \n",
       "29   “When a child first catches adults out -- when...   \n",
       "..                                                 ...   \n",
       "108  \"I lost track after a while, happy to be home,...   \n",
       "109  \"The men began singing, a grave, slow song tha...   \n",
       "110  \"'When the day shall come, that we do part,' h...   \n",
       "111  \"I lingered round them, under that benign sky;...   \n",
       "112  \"His body stirs beneath the sheets. He twists ...   \n",
       "113  ''I never saw any of them again — except the c...   \n",
       "114  \"She watched as Sandy Forsyth walked across th...   \n",
       "115  \"I went on my way. A stormy wind rattled the s...   \n",
       "116  \"This is not a full circle. It's Life carrying...   \n",
       "117  \"Yes, they will trample me underfoot, the numb...   \n",
       "118  \"The white floodlight shines through the wispy...   \n",
       "119  \"It was then that I began to sit on my bed and...   \n",
       "120  \"He now has more patients than the devil himse...   \n",
       "121  \"He turned away to give them time to pull them...   \n",
       "122  \"Of course, it's only superstition, just for f...   \n",
       "123  \"And here she is, herself, Clarissa, not Mrs. ...   \n",
       "124  \"The broken flower drooped over Ben's fist and...   \n",
       "125  \"'Rest assured, our father, rest assured. The ...   \n",
       "126  \"This stone is entirely blank. The only though...   \n",
       "127  \"Slowly, very slowly, like two unhurried compa...   \n",
       "128  \"I got to light out for the Territory ahead of...   \n",
       "129  \"Lastly, she pictured to herself how this same...   \n",
       "130  \"When they finally did dare it, at first with ...   \n",
       "131  \"And so we stayed out in the garden of the old...   \n",
       "132  \"But, in spite of these deficiencies, the wish...   \n",
       "133  \"Archie, for one, watched the mouse. He watche...   \n",
       "134  \"Might I trouble you then to be ready in half ...   \n",
       "135  \"My personal rollercoaster. Not so much a roll...   \n",
       "136  \"The offing was barred by a black bank of clou...   \n",
       "137  \"He didn't think about it, he went straight to...   \n",
       "\n",
       "                                                  info google_dates  \n",
       "0                                   A Farewell to Arms       [1929]  \n",
       "1                          Dickens, Great Expectations       [1861]  \n",
       "2                                          Jack London       [1916]  \n",
       "3                     Umberto Eco, Foucault's Pendulum       [1988]  \n",
       "4                             The Sandman, Neil Gaiman           []  \n",
       "5                                             Catch 22       [1961]  \n",
       "6                               The Patrician Vetinari           []  \n",
       "7                                         Gary Provost           []  \n",
       "8                  Sense of an Ending by Julian Barnes       [2011]  \n",
       "9                  The Amber Spyglass, Phillip Paulman       [2000]  \n",
       "10                           Carl Sagan, Pale Blue Dot       [1994]  \n",
       "11                 Return of the King by J.R.R Tolkien       [1955]  \n",
       "12    Hunter S Thompson, Fear and loathing in Las V...       [1971]  \n",
       "13     Robert A. Heinlein,  Stranger in a Strange Land       [1961]  \n",
       "14                    Albert Camus, *Return to Tipasa*           []  \n",
       "15                               To Kill a Mockingbirg       [1960]  \n",
       "16                                          T.S. Eliot           []  \n",
       "17                                   A Game of Thrones           []  \n",
       "18                           On the Road, Jack Kerouac       [1951]  \n",
       "19               All the Kings Men, Robert Penn Warren       [1946]  \n",
       "20              Joseph Conrad,  \"The Heart of Darkness       [1902]  \n",
       "21                 The Fell Sword, by Miles Cameron          [2013]  \n",
       "22                    Hitchhiker's Guide to the Galaxy           []  \n",
       "23                       One Hundred Years of Solitude           []  \n",
       "24                P.G. Wodehouse, *Joy in the Morning*       [1946]  \n",
       "25                          Kurt Vonnegut, Cats Cradle       [1963]  \n",
       "26         The Return of the King, by J. R. R. Tolkien       [1955]  \n",
       "27                                      Farrenheit 451       [1953]  \n",
       "28                                   Heart of Darkness       [1902]  \n",
       "29    Steinbeck, East of EdenThat book is filled wi...           []  \n",
       "..                                                 ...          ...  \n",
       "108                                          Middlesex           []  \n",
       "109                                    Suite Francaise       [2004]  \n",
       "110                                    The Fiery Cross       [2001]  \n",
       "111                                  Wuthering Heights       [1847]  \n",
       "112                      The Hand That First Held Mine       [2009]  \n",
       "113                                   The Long Goodbye       [1953]  \n",
       "114                                   Winter in Madrid       [2006]  \n",
       "115                                        The Pianist           []  \n",
       "116                 Don't Let's Go to the Dogs Tonight       [2001]  \n",
       "117                                Midnight's Children           []  \n",
       "118                             A Hundred and One Days       [2003]  \n",
       "119                                   Cider With Rosie       [1959]  \n",
       "120                                      Madame Bovary       [1856]  \n",
       "121                                  Lord of the Flies       [1954]  \n",
       "122                             The Kitchen God's Wife       [1991]  \n",
       "123                                          The Hours       [1998]  \n",
       "124                             The Sound and the Fury           []  \n",
       "125                                     The Good Earth       [1931]  \n",
       "126                                     Les Miserables       [1862]  \n",
       "127                                    Brave New World       [1932]  \n",
       "128                     Adventures of Huckleberry Finn       [1884]  \n",
       "129                   Alice's Adventures in Wonderland       [1865]  \n",
       "130                   Perfume: The Story of a Murderer       [1985]  \n",
       "131                                       Man and Wife       [1870]  \n",
       "132                                               Emma       [1815]  \n",
       "133                                        White Teeth           []  \n",
       "134                      The Hound of the Baskervilles       [1902]  \n",
       "135                                    Any Human Heart       [2002]  \n",
       "136                                  Heart of Darkness       [1902]  \n",
       "137                                        The Outcast       [1918]  \n",
       "\n",
       "[138 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape for DuckDuckGo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_sq = []\n",
    "for item in title_list:\n",
    "    dd_sq.append(f'what date was {item} published?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_date = []\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "for p in dd_sq:\n",
    "    browser.get('http://www.duckduckgo.com')\n",
    "    search = browser.find_element_by_xpath(\".//input[@id='search_form_input_homepage']\")\n",
    "    search.send_keys(f'{p}')\n",
    "    search.send_keys(Keys.RETURN) # hit return after you enter search text\n",
    "    time.sleep(5) # sleep for 5 seconds \n",
    "    \n",
    "    try:\n",
    "        result = browser.find_element_by_xpath('.//span[@class=\"js-about-item-abstr\"]')\n",
    "        result = result.get_attribute('innerHTML')\n",
    "    except:\n",
    "        result = 'NaN'\n",
    "\n",
    "    dd_date.append(result)\n",
    "\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_date\n",
    "df['duck_dates'] = extract_years(dd_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape for Ask.com\n",
    "\n",
    "ask_dates = []\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "for p in dd_sq:\n",
    "    browser.get('http://www.ask.com')\n",
    "    search = browser.find_element_by_name('q')\n",
    "    search.send_keys(f'{p}')\n",
    "    search.send_keys(Keys.RETURN) # hit return after you enter search text\n",
    "    time.sleep(10) # sleep for 5 seconds so you can see the results\n",
    "    \n",
    "    try:\n",
    "        result = browser.find_element_by_xpath('.//p[@class=\"PartialSearchResults-item-abstract\"]')\n",
    "        result = result.get_attribute('innerHTML')\n",
    "    except:\n",
    "        result = 'NaN'\n",
    "\n",
    "    ask_dates.append(result)\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ask_dates'] = extract_years(ask_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/reddit_df_with_scraped_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>info</th>\n",
       "      <th>duck_dates</th>\n",
       "      <th>ask_dates</th>\n",
       "      <th>google_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Really, the whole paragraph is good, but in pa...</td>\n",
       "      <td>A Farewell to Arms</td>\n",
       "      <td>['1929']</td>\n",
       "      <td>['1929']</td>\n",
       "      <td>[1929]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I looked at the stars, and considered how awf...</td>\n",
       "      <td>Dickens, Great Expectations</td>\n",
       "      <td>[]</td>\n",
       "      <td>['1860', '1861']</td>\n",
       "      <td>[1861]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"As the days went by, the evolution of like in...</td>\n",
       "      <td>Jack London</td>\n",
       "      <td>[]</td>\n",
       "      <td>['2019']</td>\n",
       "      <td>[1916]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Where else? I belong to a lost generation and...</td>\n",
       "      <td>Umberto Eco, Foucault's Pendulum</td>\n",
       "      <td>['1988']</td>\n",
       "      <td>['1988', '1988', '1989']</td>\n",
       "      <td>[1988]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;gt;Have you ever been in love? Horrible isn't...</td>\n",
       "      <td>The Sandman, Neil Gaiman</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Really, the whole paragraph is good, but in pa...   \n",
       "1  \"I looked at the stars, and considered how awf...   \n",
       "2  \"As the days went by, the evolution of like in...   \n",
       "3  \"Where else? I belong to a lost generation and...   \n",
       "4  &gt;Have you ever been in love? Horrible isn't...   \n",
       "\n",
       "                                info duck_dates                 ask_dates  \\\n",
       "0                 A Farewell to Arms   ['1929']                  ['1929']   \n",
       "1        Dickens, Great Expectations         []          ['1860', '1861']   \n",
       "2                        Jack London         []                  ['2019']   \n",
       "3   Umberto Eco, Foucault's Pendulum   ['1988']  ['1988', '1988', '1989']   \n",
       "4           The Sandman, Neil Gaiman         []                        []   \n",
       "\n",
       "  google_dates  \n",
       "0       [1929]  \n",
       "1       [1861]  \n",
       "2       [1916]  \n",
       "3       [1988]  \n",
       "4           []  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Liberty Fund (NonFiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://oll.libertyfund.org/groups/44'\n",
    "res = requests.get(url)\n",
    "\n",
    "soup = bs(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slugs = []\n",
    "links_for_books = []\n",
    "list_of_sites = []\n",
    "text_info = []\n",
    "\n",
    "for link in soup.find_all('li'):\n",
    "    l = link.find('a')\n",
    "    slugs.append(l)\n",
    "\n",
    "for row in slugs:\n",
    "    r = str(row)\n",
    "    link = re.findall(r'\"(.*?)\"', r)\n",
    "    links_for_books.append(link)\n",
    "\n",
    "for slug in links_for_books:\n",
    "    slugname = str(slug[0])\n",
    "    link = f'https://oll.libertyfund.org/titles{slugname}'\n",
    "    print(f'scraping{link}')\n",
    "       \n",
    "    res = requests.get(link)\n",
    "    soup = bs(res.content, 'lxml')\n",
    "    words = soup.get_text()[1000:2000]\n",
    "    text = words.strip()\n",
    "    text = text.replace('\\n', '')\n",
    "    text_info.append(text)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olf_df = pd.DataFrame(text_info)\n",
    "# olf_df.to_csv('olf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
