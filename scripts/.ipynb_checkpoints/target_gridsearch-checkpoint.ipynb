{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, RandomUnderSampler, EditedNearestNeighbours, RepeatedEditedNearestNeighbours\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# df = pd.read_csv('../data/cleaned/final_df.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1644,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_book_df3.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('final_book_df3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>info</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1850</td>\n",
       "      <td>['FreedomPamphlet.', 'PRICEONEPENNY.', 'THERIG...</td>\n",
       "      <td>those from whom it proceeds are the masters of...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1861</td>\n",
       "      <td>[\"Lincoln'sFirstInauguralAddress\", 'March4,186...</td>\n",
       "      <td>by some action not provided for in the instrum...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1841</td>\n",
       "      <td>['BARNABYRUDGE', \"ATALEOFTHERIOTSOF'EIGHTY\", '...</td>\n",
       "      <td>edith in a speech in parliament on frequent ex...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1854</td>\n",
       "      <td>['HIMALAYANJOURNALS', 'or', 'NOTESOFANATURALIS...</td>\n",
       "      <td>dgeworthia crab apple chameleon and porcupine ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1911</td>\n",
       "      <td>['THETALEOF', 'TIMMYTIPTOES', '[Illustration]'...</td>\n",
       "      <td>goody tiptoes but where is chippy hackee my hu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>1920</td>\n",
       "      <td>Farcical History of Richard Greenow</td>\n",
       "      <td>t is possible for those who desire it incredib...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1920</td>\n",
       "      <td>The Death of Lully</td>\n",
       "      <td>he young man returned to his couch under the a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1880</td>\n",
       "      <td>The Revolutionary's Handbook</td>\n",
       "      <td>great rulers cannot do codes and religions can...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>1922</td>\n",
       "      <td>The DIamond as big as the ritz</td>\n",
       "      <td>john s first two years there passed pleasantly...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1985</td>\n",
       "      <td>the handmaids tale</td>\n",
       "      <td>falling in love we said i fell for him we were...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>1982</td>\n",
       "      <td>the colour purple</td>\n",
       "      <td>here s the thing say shug the thing i believe ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date                                               info  \\\n",
       "482  1850  ['FreedomPamphlet.', 'PRICEONEPENNY.', 'THERIG...   \n",
       "483  1861  [\"Lincoln'sFirstInauguralAddress\", 'March4,186...   \n",
       "489  1841  ['BARNABYRUDGE', \"ATALEOFTHERIOTSOF'EIGHTY\", '...   \n",
       "498  1854  ['HIMALAYANJOURNALS', 'or', 'NOTESOFANATURALIS...   \n",
       "564  1911  ['THETALEOF', 'TIMMYTIPTOES', '[Illustration]'...   \n",
       "578  1920                Farcical History of Richard Greenow   \n",
       "642  1920                                 The Death of Lully   \n",
       "688  1880                       The Revolutionary's Handbook   \n",
       "729  1922                     The DIamond as big as the ritz   \n",
       "955  1985                                 the handmaids tale   \n",
       "960  1982                                  the colour purple   \n",
       "\n",
       "                                                  text  target  \n",
       "482  those from whom it proceeds are the masters of...       2  \n",
       "483  by some action not provided for in the instrum...       2  \n",
       "489  edith in a speech in parliament on frequent ex...       2  \n",
       "498  dgeworthia crab apple chameleon and porcupine ...       2  \n",
       "564  goody tiptoes but where is chippy hackee my hu...       4  \n",
       "578  t is possible for those who desire it incredib...       4  \n",
       "642  he young man returned to his couch under the a...       4  \n",
       "688  great rulers cannot do codes and religions can...       2  \n",
       "729  john s first two years there passed pleasantly...       4  \n",
       "955  falling in love we said i fell for him we were...       5  \n",
       "960  here s the thing say shug the thing i believe ...       5  "
      ]
     },
     "execution_count": 1698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated(subset=['text'])][50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962, 4)"
      ]
     },
     "execution_count": 1708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1707,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['text'], keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1709,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "st = df['text'].tolist()\n",
    "\n",
    "\n",
    "def clean_text(raw_text):\n",
    "    raw_text = str(raw_text)\n",
    "    lower_case = raw_text.lower()\n",
    "    retokenizer = RegexpTokenizer(r'[a-z]+')\n",
    "    words = retokenizer.tokenize(lower_case)\n",
    "    \n",
    "    return(lemmatizer.lemmatize(\" \".join(words)))\n",
    "\n",
    "num_excerpts = df['text'].size\n",
    "\n",
    "clean_text_excerpts = []\n",
    "\n",
    "for i in range(0, num_excerpts):\n",
    "     clean_text_excerpts.append( clean_text( st[i] ))\n",
    "\n",
    "\n",
    "df['text'] = clean_text_excerpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1710,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_list = [\n",
    "    [0, 1670, 1800, 1870, 1910, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1870, 1910, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1870, 1920, 1945, np.inf],\n",
    "    [0, 1670, 1800, 1870, 1920, 1945, np.inf],\n",
    "    [0, 1670, 1800, 1870, 1920, 1960, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1920, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1920, 1950, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1910, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1930, 1975, np.inf],\n",
    "    [0, 1700, 1800, 1870, 1910, 1945, np.inf],\n",
    "    [0, 1700, 1830, 1890, 1910, 1945, np.inf],\n",
    "    [0, 1700, 1830, 1870, 1920, 1945, np.inf],\n",
    "    [0, 1670, 1830, 1870, 1920, 1975, np.inf],\n",
    "    [0, 1670, 1830, 1890, 1920, 1975, np.inf],\n",
    "    [0, 1600, 1700, 1800, 1900, 1950, np.inf],\n",
    "    [0, 1670, 1830, 1920, 1950, 1990, np.inf],\n",
    "    [0, 1700, 1830, 1890, 1910, 1945, np.inf]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english',\n",
    "                        lowercase=True,\n",
    "                        ngram_range=(1, 3),\n",
    "                        strip_accents='unicode')\n",
    "\n",
    "tvec = TfidfVectorizer(stop_words='english',\n",
    "                        ngram_range=(1, 3),\n",
    "                        encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1712,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets(bin_list, model, vectorizer, df=df):\n",
    "    for b in bin_list:\n",
    "        bins = b\n",
    "        bin_names = range(0, 6)\n",
    "        df['target'] = pd.cut(df['date'], bins, labels=bin_names)\n",
    "        df.groupby('target').count()\n",
    "\n",
    "        #train test split\n",
    "        x = df['text']\n",
    "        y = df['target']\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.8, random_state=42, shuffle=True, stratify=y)\n",
    "        \n",
    "        #using countvectorizer on the x_train and x_test\n",
    "        train_data = vectorizer.fit_transform(x_train.apply(lambda x: np.str_(x)))\n",
    "        test_data = vectorizer.transform(x_test.apply(lambda x: np.str_(x)))\n",
    "        \n",
    "        \n",
    "        #instantiating, fitting, and scoring the model\n",
    "        model = model\n",
    "        model.fit(train_data, y_train)\n",
    "        score = model.score(test_data, y_test)\n",
    "        print(f' Accuracy of Bin {bins}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of Bin [0, 1670, 1800, 1870, 1910, 1945, inf]: 0.6683937823834197\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1910, 1945, inf]: 0.6424870466321243\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1945, inf]: 0.6528497409326425\n",
      " Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1945, inf]: 0.6839378238341969\n",
      " Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1960, inf]: 0.6735751295336787\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1945, inf]: 0.6735751295336787\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1950, inf]: 0.6424870466321243\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1910, 1945, inf]: 0.689119170984456\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1930, 1975, inf]: 0.6787564766839378\n",
      " Accuracy of Bin [0, 1700, 1800, 1870, 1910, 1945, inf]: 0.6735751295336787\n",
      " Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.6683937823834197\n",
      " Accuracy of Bin [0, 1700, 1830, 1870, 1920, 1945, inf]: 0.6217616580310881\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1975, inf]: 0.616580310880829\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1975, inf]: 0.6217616580310881\n",
      " Accuracy of Bin [0, 1600, 1700, 1800, 1900, 1950, inf]: 0.5958549222797928\n",
      " Accuracy of Bin [0, 1670, 1830, 1920, 1950, 1990, inf]: 0.6580310880829016\n",
      " Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.6683937823834197\n"
     ]
    }
   ],
   "source": [
    "make_targets(bin_list, model=LogisticRegression(class_weight='balanced'), vectorizer=cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of Bin [0, 1670, 1800, 1870, 1910, 1945, inf]: 0.5365853658536586\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1910, 1945, inf]: 0.5756097560975609\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1945, inf]: 0.624390243902439\n",
      " Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1945, inf]: 0.5902439024390244\n",
      " Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1960, inf]: 0.5560975609756098\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1945, inf]: 0.5560975609756098\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1950, inf]: 0.6292682926829268\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1910, 1945, inf]: 0.5853658536585366\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1930, 1975, inf]: 0.5951219512195122\n",
      " Accuracy of Bin [0, 1700, 1800, 1870, 1910, 1945, inf]: 0.5414634146341464\n",
      " Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.5609756097560976\n",
      " Accuracy of Bin [0, 1700, 1830, 1870, 1920, 1945, inf]: 0.6048780487804878\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1975, inf]: 0.6097560975609756\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1975, inf]: 0.6390243902439025\n",
      " Accuracy of Bin [0, 1600, 1700, 1800, 1900, 1950, inf]: 0.6439024390243903\n",
      " Accuracy of Bin [0, 1670, 1830, 1920, 1950, 1990, inf]: 0.5951219512195122\n",
      " Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.5756097560975609\n"
     ]
    }
   ],
   "source": [
    "make_targets(bin_list, model=RandomForestClassifier(), vectorizer=cvec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of Bin [0, 1670, 1800, 1870, 1910, 1945, inf]: 0.7912621359223301\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1910, 1945, inf]: 0.7669902912621359\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1945, inf]: 0.7669902912621359\n",
      " Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1945, inf]: 0.7864077669902912\n",
      " Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1960, inf]: 0.7087378640776699\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1945, inf]: 0.7621359223300971\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1950, inf]: 0.7524271844660194\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1910, 1945, inf]: 0.7524271844660194\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1930, 1975, inf]: 0.7038834951456311\n",
      " Accuracy of Bin [0, 1700, 1800, 1870, 1910, 1945, inf]: 0.7427184466019418\n",
      " Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.7669902912621359\n",
      " Accuracy of Bin [0, 1700, 1830, 1870, 1920, 1945, inf]: 0.7912621359223301\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1975, inf]: 0.6941747572815534\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1975, inf]: 0.7524271844660194\n",
      " Accuracy of Bin [0, 1600, 1700, 1800, 1900, 1950, inf]: 0.7912621359223301\n",
      " Accuracy of Bin [0, 1670, 1830, 1920, 1950, 1990, inf]: 0.7330097087378641\n",
      " Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.7378640776699029\n"
     ]
    }
   ],
   "source": [
    "make_targets(bin_list, model=RandomForestClassifier(), vectorizer=tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of Bin [0, 1670, 1800, 1870, 1910, 1945, inf]: 0.8543689320388349\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1910, 1945, inf]: 0.8349514563106796\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1945, inf]: 0.8155339805825242\n",
      " Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1945, inf]: 0.8398058252427184\n",
      " Accuracy of Bin [0, 1670, 1800, 1870, 1920, 1960, inf]: 0.8106796116504854\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1945, inf]: 0.8252427184466019\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1950, inf]: 0.8349514563106796\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1910, 1945, inf]: 0.8058252427184466\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1930, 1975, inf]: 0.7281553398058253\n",
      " Accuracy of Bin [0, 1700, 1800, 1870, 1910, 1945, inf]: 0.8446601941747572\n",
      " Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.7912621359223301\n",
      " Accuracy of Bin [0, 1700, 1830, 1870, 1920, 1945, inf]: 0.8203883495145631\n",
      " Accuracy of Bin [0, 1670, 1830, 1870, 1920, 1975, inf]: 0.7669902912621359\n",
      " Accuracy of Bin [0, 1670, 1830, 1890, 1920, 1975, inf]: 0.7621359223300971\n",
      " Accuracy of Bin [0, 1600, 1700, 1800, 1900, 1950, inf]: 0.7912621359223301\n",
      " Accuracy of Bin [0, 1670, 1830, 1920, 1950, 1990, inf]: 0.7038834951456311\n",
      " Accuracy of Bin [0, 1700, 1830, 1890, 1910, 1945, inf]: 0.7912621359223301\n"
     ]
    }
   ],
   "source": [
    "make_targets(bin_list, model=LogisticRegression(class_weight='balanced'), vectorizer=tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('rebalanced_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>info</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  info  text\n",
       "target                  \n",
       "0        147   147   147\n",
       "1        130   130   130\n",
       "2        156   156   156\n",
       "3        201   201   201\n",
       "4        149   149   149\n",
       "5         60    60    60\n",
       "6        119   119   119"
      ]
     },
     "execution_count": 1722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 1670, 1800, 1870, 1920, 1945, np.inf]\n",
    "names = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "df['target'] = pd.cut(df['date'], bins, labels=names)\n",
    "\n",
    "\n",
    "df.groupby('target').count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.8, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english',\n",
    "                        lowercase=True,\n",
    "                        ngram_range=(1, 3),\n",
    "                        strip_accents='unicode')\n",
    "\n",
    "x_train = cvec.fit_transform(x_train.apply(lambda x: np.str_(x)))\n",
    "\n",
    "\n",
    "\n",
    "x_test = cvec.transform(x_test.apply(lambda x: np.str_(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5107212475633528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'multi_class': 'warn',\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr_params = {\n",
    "    'solver': ['lbfgs', 'sag'],\n",
    "    'class_weight': ['balanced'],\n",
    "    'multi_class': ['multinomial', 'auto', 'warn'],\n",
    "    'penalty': ['none', 'l2']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(lr, param_grid=lr_params)\n",
    "gs.fit(x_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/cleaned/final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalance Learn Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1724,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance_train_test_logreg(x, y, rebalance_alg, algorithm_name):\n",
    "\n",
    "    \n",
    "    # Rebalance train data\n",
    "    rebalance = rebalance_alg\n",
    "    x_reb, y_reb = rebalance.fit_sample(x_train, y_train)\n",
    "\n",
    "    # Train a Logistic Regression model on resampled data\n",
    "    logreg = LogisticRegression(solver = 'lbfgs', multi_class = 'auto')\n",
    "    logreg.fit(x_reb, y_reb)\n",
    "\n",
    "    # Generate predictions\n",
    "    y_pred = logreg.predict(x_test)\n",
    "\n",
    "    # Print out metrics\n",
    "    print(f' Accuracy Score: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f' Precision Score: {precision_score(y_test, y_pred, average = None)}')\n",
    "    print(f' Recall Score: {recall_score(y_test, y_pred, average = None)}')\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy Score: 0.5233160621761658\n",
      " Precision Score: [0.65714286 0.59259259 0.4516129  0.75862069 0.44827586 0.15789474\n",
      " 0.43478261]\n",
      " Recall Score: [0.76666667 0.61538462 0.4516129  0.55       0.43333333 0.25\n",
      " 0.41666667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 4, 0, 2, 6, 1, 1, 2, 1, 1, 3, 5, 3, 5, 0, 3, 6, 0, 4, 2, 0,\n",
       "       0, 2, 4, 3, 5, 0, 0, 0, 0, 3, 4, 6, 3, 5, 1, 4, 2, 3, 3, 1, 1, 2,\n",
       "       1, 4, 6, 4, 3, 1, 1, 4, 2, 0, 5, 5, 0, 2, 2, 0, 3, 2, 0, 6, 4, 3,\n",
       "       2, 4, 3, 3, 4, 4, 1, 0, 0, 2, 1, 4, 3, 6, 5, 3, 2, 5, 5, 1, 1, 2,\n",
       "       6, 1, 0, 6, 0, 0, 1, 1, 6, 5, 3, 6, 4, 6, 5, 0, 0, 2, 2, 4, 4, 3,\n",
       "       2, 0, 0, 2, 5, 5, 2, 4, 6, 0, 4, 1, 4, 6, 5, 2, 2, 0, 4, 3, 2, 1,\n",
       "       1, 3, 3, 4, 3, 6, 3, 3, 4, 2, 0, 4, 3, 3, 1, 4, 6, 4, 2, 6, 0, 5,\n",
       "       6, 6, 0, 1, 2, 0, 1, 2, 3, 1, 4, 0, 5, 0, 2, 6, 6, 2, 0, 2, 1, 6,\n",
       "       5, 0, 2, 4, 0, 4, 0, 1, 0, 5, 3, 5, 6, 6, 2, 3, 4])"
      ]
     },
     "execution_count": 1725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebalance_train_test_logreg(x_train, y_train, SMOTE(), 'SMOTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No samples will be generated with the provided ratio settings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1726-e6b906f92183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrebalance_train_test_logreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mADASYN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADASYN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1724-3461005c0dfe>\u001b[0m in \u001b[0;36mrebalance_train_test_logreg\u001b[0;34m(x, y, rebalance_alg, algorithm_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Rebalance train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrebalance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrebalance_alg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx_reb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_reb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrebalance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Train a Logistic Regression model on resampled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m             self.sampling_strategy, y, self._sampling_type)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mn_samples_generate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio_nn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 raise ValueError(\"No samples will be generated with the\"\n\u001b[0m\u001b[1;32m    132\u001b[0m                                  \" provided ratio settings.\")\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No samples will be generated with the provided ratio settings."
     ]
    }
   ],
   "source": [
    "rebalance_train_test_logreg(x_train, y_train, ADASYN(), 'ADASYN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy Score: 0.538860103626943\n",
      " Precision Score: [0.62162162 0.57692308 0.61111111 0.75       0.53571429 0.13636364\n",
      " 0.38461538]\n",
      " Recall Score: [0.76666667 0.57692308 0.35483871 0.675      0.5        0.25\n",
      " 0.41666667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 4, 0, 3, 6, 1, 0, 3, 0, 2, 3, 1, 1, 5, 6, 1, 4, 0, 4, 3, 0,\n",
       "       0, 3, 4, 3, 5, 0, 0, 0, 0, 3, 4, 6, 3, 5, 1, 4, 3, 3, 3, 1, 1, 0,\n",
       "       1, 4, 6, 4, 4, 1, 1, 4, 2, 4, 5, 5, 6, 2, 2, 2, 3, 3, 0, 0, 0, 4,\n",
       "       1, 6, 3, 2, 4, 5, 1, 0, 0, 2, 1, 6, 3, 6, 5, 3, 6, 5, 5, 1, 1, 3,\n",
       "       6, 1, 0, 6, 0, 0, 1, 3, 6, 5, 3, 5, 5, 4, 5, 0, 0, 2, 2, 4, 4, 3,\n",
       "       2, 0, 3, 2, 5, 5, 4, 0, 6, 0, 4, 1, 2, 2, 5, 4, 3, 6, 4, 3, 4, 1,\n",
       "       2, 3, 4, 5, 3, 6, 3, 3, 4, 6, 0, 4, 3, 3, 2, 2, 6, 3, 1, 5, 0, 5,\n",
       "       6, 6, 0, 0, 0, 0, 1, 4, 3, 1, 6, 0, 6, 0, 2, 6, 6, 3, 3, 1, 1, 6,\n",
       "       5, 0, 2, 4, 0, 4, 0, 1, 0, 6, 3, 5, 5, 6, 0, 3, 4])"
      ]
     },
     "execution_count": 1727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebalance_train_test_logreg(x_train, y_train, BorderlineSMOTE(), 'BorderlineSMOTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy Score: 0.5751295336787565\n",
      " Precision Score: [0.66666667 0.56666667 0.64       0.72727273 0.61538462 0.15789474\n",
      " 0.5       ]\n",
      " Recall Score: [0.66666667 0.65384615 0.51612903 0.6        0.53333333 0.25\n",
      " 0.625     ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 4, 6, 3, 6, 1, 0, 2, 2, 1, 3, 5, 1, 5, 6, 3, 6, 0, 4, 2, 0,\n",
       "       5, 3, 4, 3, 5, 0, 0, 0, 0, 3, 4, 6, 3, 6, 1, 4, 2, 3, 3, 6, 1, 0,\n",
       "       1, 4, 6, 4, 3, 1, 1, 4, 2, 0, 5, 5, 0, 2, 2, 2, 3, 2, 0, 6, 4, 4,\n",
       "       1, 4, 3, 3, 4, 5, 1, 0, 6, 2, 1, 4, 3, 6, 5, 3, 0, 2, 5, 6, 1, 0,\n",
       "       6, 1, 0, 6, 0, 0, 1, 3, 6, 5, 3, 2, 6, 6, 5, 0, 0, 2, 2, 4, 4, 3,\n",
       "       2, 0, 2, 2, 6, 6, 4, 1, 6, 0, 4, 1, 1, 6, 5, 0, 3, 0, 4, 3, 2, 1,\n",
       "       1, 3, 3, 4, 3, 6, 3, 3, 1, 4, 0, 4, 3, 3, 1, 2, 6, 4, 1, 6, 0, 5,\n",
       "       6, 6, 1, 1, 2, 1, 1, 3, 3, 2, 0, 5, 5, 5, 4, 4, 5, 2, 3, 1, 2, 6,\n",
       "       5, 0, 2, 1, 0, 4, 0, 1, 0, 6, 3, 5, 6, 6, 2, 3, 4])"
      ]
     },
     "execution_count": 1728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebalance_train_test_logreg(x_train, y_train, SMOTETomek(), 'SMOTETomek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
